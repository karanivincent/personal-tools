{
    "url": "https://microsoft.github.io/autogen/blog/2023/10/26/TeachableAgent",
    "title": "AutoGen's Teachable Agents",
    "sections": [
        {
            "title": "",
            "content": [
                {
                    "text": "\n\nTL;DR:"
                }
            ],
            "subsections": []
        },
        {
            "title": "Introduction\n​",
            "content": [
                {
                    "text": "Conversational assistants based on LLMs can remember the current chat with the user, and can also demonstrate in-context learning of user teachings during the conversation. But the assistant's memories and learnings are lost once the chat is over, or when a single chat grows too long for the LLM to handle effectively. Then in subsequent chats the user is forced to repeat any necessary instructions over and over.\n\nTeachability\naddresses these limitations by persisting user teachings across chat boundaries in long-term memory implemented as a vector database. Instead of copying all of memory into the context window, which would eat up valuable space, individual memories (called memos) are retrieved into context as needed. This allows the user to teach frequently used facts and skills to the teachable agent just once, and have it recall them in later chats.\n\nAny instantiated\nagent\nthat inherits from\nConversableAgent\ncan be made teachable by instantiating a\nTeachability\nobject and calling its\nadd_to_agent(agent)\nmethod.\nIn order to make effective decisions about memo storage and retrieval, the\nTeachability\nobject calls an instance of\nTextAnalyzerAgent\n(another AutoGen agent) to identify and reformulate text as needed for remembering facts, preferences, and skills. Note that this adds extra LLM calls involving a relatively small number of tokens, which can add a few seconds to the time a user waits for each response."
                }
            ],
            "subsections": []
        },
        {
            "title": "Run It Yourself\n​",
            "content": [
                {
                    "text": "AutoGen contains four code examples that use\nTeachability\n.\n\nRun\nchat_with_teachable_agent.py\nto converse with a teachable agent.\n\nRun\ntest_teachable_agent.py\nfor quick unit testing of a teachable agent.\n\nUse the Jupyter notebook\nagentchat_teachability.ipynb\nto step through examples discussed below.\n\nUse the Jupyter notebook\nagentchat_teachable_oai_assistants.ipynb\nto make arbitrary OpenAI Assistants teachable through\nGPTAssistantAgent\n."
                }
            ],
            "subsections": []
        },
        {
            "title": "Basic Usage of Teachability\n​",
            "content": [
                {
                    "text": "Please install pyautogen with the [teachable] option before using\nTeachability\n."
                },
                {
                    "code": {
                        "language": "bash",
                        "script": "pip install \"pyautogen[teachable]\""
                    }
                },
                {
                    "code": {
                        "language": "python",
                        "script": "from\nautogen\nimport\nUserProxyAgent\n,\nconfig_list_from_json\nfrom\nautogen\n.\nagentchat\n.\ncontrib\n.\ncapabilities\n.\nteachability\nimport\nTeachability\nfrom\nautogen\nimport\nConversableAgent\n# As an example"
                    }
                },
                {
                    "code": {
                        "language": "python",
                        "script": "# Load LLM inference endpoints from an env variable or a file\n# See https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints\n# and OAI_CONFIG_LIST_sample\nfilter_dict\n=\n{\n\"model\"\n:\n[\n\"gpt-4\"\n]\n}\n# GPT-3.5 is less reliable than GPT-4 at learning from user feedback.\nconfig_list\n=\nconfig_list_from_json\n(\nenv_or_file\n=\n\"OAI_CONFIG_LIST\"\n,\nfilter_dict\n=\nfilter_dict\n)\nllm_config\n=\n{\n\"config_list\"\n:\nconfig_list\n,\n\"timeout\"\n:\n120\n}"
                    }
                },
                {
                    "code": {
                        "language": "python",
                        "script": "# Start by instantiating any agent that inherits from ConversableAgent, which we use directly here for simplicity.\nteachable_agent\n=\nConversableAgent\n(\nname\n=\n\"teachable_agent\"\n,\n# The name can be anything.\nllm_config\n=\nllm_config\n)\n# Instantiate a Teachability object. Its parameters are all optional.\nteachability\n=\nTeachability\n(\nreset_db\n=\nFalse\n,\n# Use True to force-reset the memo DB, and False to use an existing DB.\npath_to_db_dir\n=\n\"./tmp/interactive/teachability_db\"\n# Can be any path, but teachable agents in a group chat require unique paths.\n)\n# Now add teachability to the agent.\nteachability\n.\nadd_to_agent\n(\nteachable_agent\n)\n# For this test, create a user proxy agent as usual.\nuser\n=\nUserProxyAgent\n(\n\"user\"\n,\nhuman_input_mode\n=\n\"ALWAYS\"\n)"
                    }
                },
                {
                    "code": {
                        "language": "python",
                        "script": "# This function will return once the user types 'exit'.\nteachable_agent\n.\ninitiate_chat\n(\nuser\n,\nmessage\n=\n\"Hi, I'm a teachable user assistant! What's on your mind?\"\n)"
                    }
                }
            ],
            "subsections": []
        },
        {
            "title": "Example 1 - Learning user info\n​",
            "content": [
                {
                    "text": "A user can teach the agent facts about themselves.\n(Note that due to their finetuning, LLMs can be reluctant to admit that they know personal information.)"
                },
                {
                    "text": "In a later conversation, the user can check whether the teachable agent remembers their name. (For readability, the user prompts and some logged notices are not repeated below.)"
                }
            ],
            "subsections": []
        },
        {
            "title": "Example 2 - Learning new facts\n​",
            "content": [
                {
                    "text": "A user can teach the agent more complex, related facts."
                },
                {
                    "text": "Then in a later chat the teachable agent can answer questions about the facts it has been taught.\n(Remember to first close the previous chat by typing 'exit'.)"
                }
            ],
            "subsections": []
        },
        {
            "title": "Example 3 - Learning user preferences\n​",
            "content": [
                {
                    "text": "A user can teach the agent how they prefer to have things done.\n\nBe aware that a message like the next one cannot be entered as a single message through a command line because it contains a newline character.\nSuch messages can be entered in a Jupyter notebook, or through some UI layer like that of ChatGPT."
                },
                {
                    "text": "Then in later chats the teacher doesn't need to reiterate their detailed preferences."
                }
            ],
            "subsections": []
        },
        {
            "title": "Example 4 - Learning new skills\n​",
            "content": [
                {
                    "text": "Users can extend the teachable agent's capabilities by teaching it new skills for accomplishing challenging tasks. It usually works best to first describe the task, then (in the same turn) provide a hint or advice for approaching the task.\n\nThe\nSparks of AGI\npaper evaluated GPT-4 on math problems like the following, which it could only solve 32% of the time. We first show a failure case, then teach the agent a strategy which lifts GPT-4's success rate above 95%."
                },
                {
                    "text": "In a later chat the user doesn't need to repeat the detailed advice."
                }
            ],
            "subsections": []
        },
        {
            "title": "Planned improvements\n​",
            "content": [],
            "subsections": []
        },
        {
            "title": "Conclusion\n​",
            "content": [
                {
                    "text": "Teachability\nis still under active research and development. For any problems you find or improvements you have in mind, please join our discussions in this repo and on our\nDiscord channel\n. We look forward to seeing how you and the rest of the community can use and improve teachable agents in AutoGen!"
                }
            ],
            "subsections": []
        }
    ],
    "images": []
}