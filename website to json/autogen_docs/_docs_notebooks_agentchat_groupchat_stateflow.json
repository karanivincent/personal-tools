{
    "url": "https://microsoft.github.io/autogen/docs/notebooks/agentchat_groupchat_stateflow",
    "title": "StateFlow: Build Workflows through State-Oriented Actions",
    "sections": [
        {
            "title": "",
            "content": [
                {
                    "text": "\n\nAutoGen offers conversable agents powered by LLM, tool or human, which\ncan be used to perform tasks collectively via automated chat. In this\nnotebook, we introduce how to use groupchat to build workflows with\nAutoGen agents from a state-oriented perspective.\n\nInstall\npyautogen\n:"
                },
                {
                    "code": {
                        "language": "bash",
                        "script": "pip install pyautogen"
                    }
                },
                {
                    "text": "For more information, please refer to the\ninstallation guide\n."
                }
            ],
            "subsections": []
        },
        {
            "title": "Set your API Endpoint\n​",
            "content": [
                {
                    "text": "The\nconfig_list_from_json\nfunction loads a list of configurations from an environment variable or\na json file."
                },
                {
                    "code": {
                        "language": "python",
                        "script": "import\nautogen\nconfig_list\n=\nautogen\n.\nconfig_list_from_json\n(\n\"OAI_CONFIG_LIST\"\n,\nfilter_dict\n=\n{\n\"tags\"\n:\n[\n\"gpt-4\"\n,\n\"gpt-4-32k\"\n]\n,\n}\n,\n)"
                    }
                },
                {
                    "text": "Learn more about configuring LLMs for agents\nhere\n."
                }
            ],
            "subsections": []
        },
        {
            "title": "A workflow for research\n​",
            "content": [
                {
                    "text": "We define the following agents: - Initializer: Start the workflow by\nsending a task. - Coder: Retrieve papers from the internet by writing\ncode. - Executor: Execute the code. - Scientist: Read the papers and\nwrite a summary.\n\nIn the Figure, we define a simple workflow for research with 4 states:\nInit, Retrieve, Reserach and End. Within each state, we will call\ndifferent agents to perform the tasks. - Init: We use the initializer to\nstart the workflow. - Retrieve: We will first call the coder to write\ncode and then call the executor to execute the code. - Research: We will\ncall the scientist to read the papers and write a summary. - End: We\nwill end the workflow.\n\nThrough customizing the speaker selection method, we can easily realize\nthe state-oriented workflow by defining the transitions between\ndifferent agents."
                },
                {
                    "code": {
                        "language": "python",
                        "script": "import\ntempfile\nfrom\nautogen\n.\ncoding\nimport\nLocalCommandLineCodeExecutor\ntemp_dir\n=\ntempfile\n.\nTemporaryDirectory\n(\n)\nexecutor\n=\nLocalCommandLineCodeExecutor\n(\ntimeout\n=\n10\n,\n# Timeout for each code execution in seconds.\nwork_dir\n=\ntemp_dir\n.\nname\n,\n# Use the temporary directory to store the code files.\n)\ngpt4_config\n=\n{\n\"cache_seed\"\n:\nFalse\n,\n# change the cache_seed for different trials\n\"temperature\"\n:\n0\n,\n\"config_list\"\n:\nconfig_list\n,\n\"timeout\"\n:\n120\n,\n}\ninitializer\n=\nautogen\n.\nUserProxyAgent\n(\nname\n=\n\"Init\"\n,\ncode_execution_config\n=\nFalse\n,\n)\ncoder\n=\nautogen\n.\nAssistantAgent\n(\nname\n=\n\"Retrieve_Action_1\"\n,\nllm_config\n=\ngpt4_config\n,\nsystem_message\n=\n\"\"\"You are the Coder. Given a topic, write code to retrieve related papers from the arXiv API, print their title, authors, abstract, and link.\nYou write python/shell code to solve tasks. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\nDon't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\nIf the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n\"\"\"\n,\n)\nexecutor\n=\nautogen\n.\nUserProxyAgent\n(\nname\n=\n\"Retrieve_Action_2\"\n,\nsystem_message\n=\n\"Executor. Execute the code written by the Coder and report the result.\"\n,\nhuman_input_mode\n=\n\"NEVER\"\n,\ncode_execution_config\n=\n{\n\"executor\"\n:\nexecutor\n}\n,\n)\nscientist\n=\nautogen\n.\nAssistantAgent\n(\nname\n=\n\"Research_Action_1\"\n,\nllm_config\n=\ngpt4_config\n,\nsystem_message\n=\n\"\"\"You are the Scientist. Please categorize papers after seeing their abstracts printed and create a markdown table with Domain, Title, Authors, Summary and Link\"\"\"\n,\n)\ndef\nstate_transition\n(\nlast_speaker\n,\ngroupchat\n)\n:\nmessages\n=\ngroupchat\n.\nmessages\nif\nlast_speaker\nis\ninitializer\n:\n# init -> retrieve\nreturn\ncoder\nelif\nlast_speaker\nis\ncoder\n:\n# retrieve: action 1 -> action 2\nreturn\nexecutor\nelif\nlast_speaker\nis\nexecutor\n:\nif\nmessages\n[\n-\n1\n]\n[\n\"content\"\n]\n==\n\"exitcode: 1\"\n:\n# retrieve --(execution failed)--> retrieve\nreturn\ncoder\nelse\n:\n# retrieve --(execution sucess)--> research\nreturn\nscientist\nelif\nlast_speaker\n==\n\"Scientist\"\n:\n# research -> end\nreturn\nNone\ngroupchat\n=\nautogen\n.\nGroupChat\n(\nagents\n=\n[\ninitializer\n,\ncoder\n,\nexecutor\n,\nscientist\n]\n,\nmessages\n=\n[\n]\n,\nmax_round\n=\n20\n,\nspeaker_selection_method\n=\nstate_transition\n,\n)\nmanager\n=\nautogen\n.\nGroupChatManager\n(\ngroupchat\n=\ngroupchat\n,\nllm_config\n=\ngpt4_config\n)"
                    }
                },
                {
                    "code": {
                        "language": "python",
                        "script": "chat_result\n=\ninitializer\n.\ninitiate_chat\n(\nmanager\n,\nmessage\n=\n\"Topic: LLM applications papers from last week. Requirement: 5 - 10 papers from different domains.\"\n)"
                    }
                },
                {
                    "code": {
                        "language": "text",
                        "script": "Init\n(\nto\nchat_manager\n)\n:\nTopic: LLM applications papers from last week. Requirement: 5 - 10 papers from different domains.\n--------------------------------------------------------------------------------\nRetrieve_Action_1\n(\nto\nchat_manager\n)\n:\nTo retrieve related papers from the arXiv API, we can use Python with the `requests` library to send a query to the API and parse the response. Below is a Python script that searches for papers related to \"LLM applications\" (Large Language Models applications) from the last week, across different domains, and prints out the required information for 5 to 10 papers.\n```python\nimport requests\nfrom datetime import datetime, timedelta\nimport feedparser\n# Define the base URL for the arXiv API\nARXIV_API_URL = \"http://export.arxiv.org/api/query?\"\n# Define the search parameters\nsearch_query = \"all:\\\"LLM applications\\\"\"\nstart = 0\nmax_results = 10\nsort_by = \"submittedDate\"\nsort_order = \"descending\"\n# Calculate the date one week ago from today\none_week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%dT%H:%M:%SZ')\n# Construct the query\nquery = f\"search_query={search_query}&start={start}&max_results={max_results}&sortBy={sort_by}&sortOrder={sort_order}&submittedDateRange={one_week_ago}-\"\n# Send the request to the arXiv API\nresponse = requests.get(ARXIV_API_URL + query)\n# Parse the response using feedparser\nfeed = feedparser.parse(response.content)\n# Print the title, authors, abstract, and link of each paper\nfor entry in feed.entries:\nprint(\"Title:\", entry.title)\nprint(\"Authors:\", ', '.join(author.name for author in entry.authors))\nprint(\"Abstract:\", entry.summary)\nprint(\"Link:\", entry.link)\nprint(\"\\n---\\n\")\n```\nThis script will print the title, authors, abstract, and link for each paper related to \"LLM applications\" that was submitted in the last week, up to a maximum of 10 papers. If you want to ensure that the papers are from different domains, you might need to manually check the categories of the papers or refine the search query to target specific domains.\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\nRetrieve_Action_2\n(\nto\nchat_manager\n)\n:\nexitcode: 0 (execution succeeded)\nCode output: Title: Adapting LLMs for Efficient Context Processing through Soft Prompt\nCompression\nAuthors: Cangqing Wang, Yutian Yang, Ruisi Li, Dan Sun, Ruicong Cai, Yuzhu Zhang, Chengqian Fu, Lillian Floyd\nAbstract: The rapid advancement of Large Language Models (LLMs) has inaugurated a\ntransformative epoch in natural language processing, fostering unprecedented\nproficiency in text generation, comprehension, and contextual scrutiny.\nNevertheless, effectively handling extensive contexts, crucial for myriad\napplications, poses a formidable obstacle owing to the intrinsic constraints of\nthe models' context window sizes and the computational burdens entailed by\ntheir operations. This investigation presents an innovative framework that\nstrategically tailors LLMs for streamlined context processing by harnessing the\nsynergies among natural language summarization, soft prompt compression, and\naugmented utility preservation mechanisms. Our methodology, dubbed\nSoftPromptComp, amalgamates natural language prompts extracted from\nsummarization methodologies with dynamically generated soft prompts to forge a\nconcise yet semantically robust depiction of protracted contexts. This\ndepiction undergoes further refinement via a weighting mechanism optimizing\ninformation retention and utility for subsequent tasks. We substantiate that\nour framework markedly diminishes computational overhead and enhances LLMs'\nefficacy across various benchmarks, while upholding or even augmenting the\ncaliber of the produced content. By amalgamating soft prompt compression with\nsophisticated summarization, SoftPromptComp confronts the dual challenges of\nmanaging lengthy contexts and ensuring model scalability. Our findings point\ntowards a propitious trajectory for augmenting LLMs' applicability and\nefficiency, rendering them more versatile and pragmatic for real-world\napplications. This research enriches the ongoing discourse on optimizing\nlanguage models, providing insights into the potency of soft prompts and\nsummarization techniques as pivotal instruments for the forthcoming generation\nof NLP solutions.\nLink: http://arxiv.org/abs/2404.04997v1\n---\nTitle: Explainable Traffic Flow Prediction with Large Language Models\nAuthors: Xusen Guo, Qiming Zhang, Mingxing Peng, Meixin Zhu, Hao, Yang\nAbstract: Traffic flow prediction is crucial for urban planning, transportation\nmanagement, and infrastructure development. However, achieving both accuracy\nand interpretability in prediction models remains challenging due to the\ncomplexity of traffic data and the inherent opacity of deep learning\nmethodologies. In this paper, we propose a novel approach, Traffic Flow\nPrediction LLM (TF-LLM), which leverages large language models (LLMs) to\ngenerate interpretable traffic flow predictions. By transferring multi-modal\ntraffic data into natural language descriptions, TF-LLM captures complex\nspatial-temporal patterns and external factors such as weather conditions,\nPoints of Interest (PoIs), date, and holidays. We fine-tune the LLM framework\nusing language-based instructions to align with spatial-temporal traffic flow\ndata. Our comprehensive multi-modal traffic flow dataset (CATraffic) in\nCalifornia enables the evaluation of TF-LLM against state-of-the-art deep\nlearning baselines. Results demonstrate TF-LLM's competitive accuracy while\nproviding intuitive and interpretable predictions. We discuss the\nspatial-temporal and input dependencies for explainable future flow\nforecasting, showcasing TF-LLM's potential for diverse city prediction tasks.\nThis paper contributes to advancing explainable traffic prediction models and\nlays a foundation for future exploration of LLM applications in transportation.\nLink: http://arxiv.org/abs/2404.02937v2\n---\nTitle: Designing Child-Centric AI Learning Environments: Insights from\nLLM-Enhanced Creative Project-Based Learning\nAuthors: Siyu Zha, Yuehan Qiao, Qingyu Hu, Zhongsheng Li, Jiangtao Gong, Yingqing Xu\nAbstract: Project-based learning (PBL) is an instructional method that is very helpful\nin nurturing students' creativity, but it requires significant time and energy\nfrom both students and teachers. Large language models (LLMs) have been proven\nto assist in creative tasks, yet much controversy exists regarding their role\nin fostering creativity. This paper explores the potential of LLMs in PBL\nsettings, with a special focus on fostering creativity. We began with an\nexploratory study involving 12 middle school students and identified five\ndesign considerations for LLM applications in PBL. Building on this, we\ndeveloped an LLM-empowered, 48-hour PBL program and conducted an instructional\nexperiment with 31 middle school students. Our results indicated that LLMs can\nenhance every stage of PBL. Additionally, we also discovered ambivalent\nperspectives among students and mentors toward LLM usage. Furthermore, we\nexplored the challenge and design implications of integrating LLMs into PBL and\nreflected on the program. By bridging AI advancements into educational\npractice, our work aims to inspire further discourse and investigation into\nharnessing AI's potential in child-centric educational settings.\nLink: http://arxiv.org/abs/2403.16159v2\n---\nTitle: The opportunities and risks of large language models in mental health\nAuthors: Hannah R. Lawrence, Renee A. Schneider, Susan B. Rubin, Maja J. Mataric, Daniel J. McDuff, Megan Jones Bell\nAbstract: Global rates of mental health concerns are rising and there is increasing\nrealization that existing models of mental healthcare will not adequately\nexpand to meet the demand. With the emergence of large language models (LLMs)\nhas come great optimism regarding their promise to create novel, large-scale\nsolutions to support mental health. Despite their nascence, LLMs have already\nbeen applied to mental health-related tasks. In this review, we summarize the\nextant literature on efforts to use LLMs to provide mental health education,\nassessment, and intervention and highlight key opportunities for positive\nimpact in each area. We then highlight risks associated with LLMs application\nto mental health and encourage adoption of strategies to mitigate these risks.\nThe urgent need for mental health support must be balanced with responsible\ndevelopment, testing, and deployment of mental health LLMs. Especially critical\nis ensuring that mental health LLMs are fine-tuned for mental health, enhance\nmental health equity, adhere to ethical standards, and that people, including\nthose with lived experience with mental health concerns, are involved in all\nstages from development through deployment. Prioritizing these efforts will\nminimize potential harms to mental health and maximize the likelihood that LLMs\nwill positively impact mental health globally.\nLink: http://arxiv.org/abs/2403.14814v2\n---\nTitle: Large Language Models for Blockchain Security: A Systematic Literature\nReview\nAuthors: Zheyuan He, Zihao Li, Sen Yang\nAbstract: Large Language Models (LLMs) have emerged as powerful tools in various\ndomains involving blockchain security (BS). Several recent studies are\nexploring LLMs applied to BS. However, there remains a gap in our understanding\nregarding the full scope of applications, impacts, and potential constraints of\nLLMs on blockchain security. To fill this gap, we conduct a literature review\non LLM4BS.\nAs the first review of LLM's application on blockchain security, our study\naims to comprehensively analyze existing research and elucidate how LLMs\ncontribute to enhancing the security of blockchain systems. Through a thorough\nexamination of scholarly works, we delve into the integration of LLMs into\nvarious aspects of blockchain security. We explore the mechanisms through which\nLLMs can bolster blockchain security, including their applications in smart\ncontract auditing, identity verification, anomaly detection, vulnerable repair,\nand so on. Furthermore, we critically assess the challenges and limitations\nassociated with leveraging LLMs for blockchain security, considering factors\nsuch as scalability, privacy concerns, and adversarial attacks. Our review\nsheds light on the opportunities and potential risks inherent in this\nconvergence, providing valuable insights for researchers, practitioners, and\npolicymakers alike.\nLink: http://arxiv.org/abs/2403.14280v2\n---\nTitle: Do Large Language Model Understand Multi-Intent Spoken Language ?\nAuthors: Shangjian Yin, Peijie Huang, Yuhong Xu, Haojing Huang, Jiatian Chen\nAbstract: This study marks a significant advancement by harnessing Large Language\nModels (LLMs) for multi-intent spoken language understanding (SLU), proposing a\nunique methodology that capitalizes on the generative power of LLMs within an\nSLU context. Our innovative technique reconfigures entity slots specifically\nfor LLM application in multi-intent SLU environments and introduces the concept\nof Sub-Intent Instruction (SII), enhancing the dissection and interpretation of\nintricate, multi-intent communication within varied domains. The resultant\ndatasets, dubbed LM-MixATIS and LM-MixSNIPS, are crafted from pre-existing\nbenchmarks. Our research illustrates that LLMs can match and potentially excel\nbeyond the capabilities of current state-of-the-art multi-intent SLU models. It\nfurther explores LLM efficacy across various intent configurations and dataset\nproportions. Moreover, we introduce two pioneering metrics, Entity Slot\nAccuracy (ESA) and Combined Semantic Accuracy (CSA), to provide an in-depth\nanalysis of LLM proficiency in this complex field.\nLink: http://arxiv.org/abs/2403.04481v2\n---\nTitle: Breaking the Language Barrier: Can Direct Inference Outperform\nPre-Translation in Multilingual LLM Applications?\nAuthors: Yotam Intrator, Matan Halfon, Roman Goldenberg, Reut Tsarfaty, Matan Eyal, Ehud Rivlin, Yossi Matias, Natalia Aizenberg\nAbstract: Large language models hold significant promise in multilingual applications.\nHowever, inherent biases stemming from predominantly English-centric\npre-training have led to the widespread practice of pre-translation, i.e.,\ntranslating non-English inputs to English before inference, leading to\ncomplexity and information loss. This study re-evaluates the need for\npre-translation in the context of PaLM2 models (Anil et al., 2023), which have\nbeen established as highly performant in multilingual tasks. We offer a\ncomprehensive investigation across 108 languages and 6 diverse benchmarks,\nincluding open-end generative tasks, which were excluded from previous similar\nstudies. Our findings challenge the pre-translation paradigm established in\nprior research, highlighting the advantages of direct inference in PaLM2.\nSpecifically, PaLM2-L consistently outperforms pre-translation in 94 out of 108\nlanguages. These findings pave the way for more efficient and effective\nmultilingual applications, alleviating the limitations associated with\npre-translation and unlocking linguistic authenticity.\nLink: http://arxiv.org/abs/2403.04792v1\n---\nTitle: SciAssess: Benchmarking LLM Proficiency in Scientific Literature\nAnalysis\nAuthors: Hengxing Cai, Xiaochen Cai, Junhan Chang, Sihang Li, Lin Yao, Changxin Wang, Zhifeng Gao, Hongshuai Wang, Yongge Li, Mujie Lin, Shuwen Yang, Jiankun Wang, Yuqi Yin, Yaqi Li, Linfeng Zhang, Guolin Ke\nAbstract: Recent breakthroughs in Large Language Models (LLMs) have revolutionized\nnatural language understanding and generation, igniting a surge of interest in\nleveraging these technologies in the field of scientific literature analysis.\nExisting benchmarks, however, inadequately evaluate the proficiency of LLMs in\nscientific literature analysis, especially in scenarios involving complex\ncomprehension and multimodal data. In response, we introduced SciAssess, a\nbenchmark tailored for the in-depth analysis of scientific literature, crafted\nto provide a thorough assessment of LLMs' efficacy. SciAssess focuses on\nevaluating LLMs' abilities in memorization, comprehension, and analysis within\nthe context of scientific literature analysis. It includes representative tasks\nfrom diverse scientific fields, such as general chemistry, organic materials,\nand alloy materials. And rigorous quality control measures ensure its\nreliability in terms of correctness, anonymization, and copyright compliance.\nSciAssess evaluates leading LLMs, including GPT-4, GPT-3.5, and Gemini,\nidentifying their strengths and aspects for improvement and supporting the\nongoing development of LLM applications in scientific literature analysis.\nSciAssess and its resources are made available at https://sci-assess.github.io,\noffering a valuable tool for advancing LLM capabilities in scientific\nliterature analysis.\nLink: http://arxiv.org/abs/2403.01976v2\n---\nTitle: Differentially Private Synthetic Data via Foundation Model APIs 2: Text\nAuthors: Chulin Xie, Zinan Lin, Arturs Backurs, Sivakanth Gopi, Da Yu, Huseyin A Inan, Harsha Nori, Haotian Jiang, Huishuai Zhang, Yin Tat Lee, Bo Li, Sergey Yekhanin\nAbstract: Text data has become extremely valuable due to the emergence of machine\nlearning algorithms that learn from it. A lot of high-quality text data\ngenerated in the real world is private and therefore cannot be shared or used\nfreely due to privacy concerns. Generating synthetic replicas of private text\ndata with a formal privacy guarantee, i.e., differential privacy (DP), offers a\npromising and scalable solution. However, existing methods necessitate DP\nfinetuning of large language models (LLMs) on private data to generate DP\nsynthetic data. This approach is not viable for proprietary LLMs (e.g.,\nGPT-3.5) and also demands considerable computational resources for open-source\nLLMs. Lin et al. (2024) recently introduced the Private Evolution (PE)\nalgorithm to generate DP synthetic images with only API access to diffusion\nmodels. In this work, we propose an augmented PE algorithm, named Aug-PE, that\napplies to the complex setting of text. We use API access to an LLM and\ngenerate DP synthetic text without any model training. We conduct comprehensive\nexperiments on three benchmark datasets. Our results demonstrate that Aug-PE\nproduces DP synthetic text that yields competitive utility with the SOTA DP\nfinetuning baselines. This underscores the feasibility of relying solely on API\naccess of LLMs to produce high-quality DP synthetic texts, thereby facilitating\nmore accessible routes to privacy-preserving LLM applications. Our code and\ndata are available at https://github.com/AI-secure/aug-pe.\nLink: http://arxiv.org/abs/2403.01749v1\n---\nTitle: SERVAL: Synergy Learning between Vertical Models and LLMs towards\nOracle-Level Zero-shot Medical Prediction\nAuthors: Jiahuan Yan, Jintai Chen, Chaowen Hu, Bo Zheng, Yaojun Hu, Jimeng Sun, Jian Wu\nAbstract: Recent development of large language models (LLMs) has exhibited impressive\nzero-shot proficiency on generic and common sense questions. However, LLMs'\napplication on domain-specific vertical questions still lags behind, primarily\ndue to the humiliation problems and deficiencies in vertical knowledge.\nFurthermore, the vertical data annotation process often requires\nlabor-intensive expert involvement, thereby presenting an additional challenge\nin enhancing the model's vertical capabilities. In this paper, we propose\nSERVAL, a synergy learning pipeline designed for unsupervised development of\nvertical capabilities in both LLMs and small models by mutual enhancement.\nSpecifically, SERVAL utilizes the LLM's zero-shot outputs as annotations,\nleveraging its confidence to teach a robust vertical model from scratch.\nReversely, the trained vertical model guides the LLM fine-tuning to enhance its\nzero-shot capability, progressively improving both models through an iterative\nprocess. In medical domain, known for complex vertical knowledge and costly\nannotations, comprehensive experiments show that, without access to any gold\nlabels, SERVAL with the synergy learning of OpenAI GPT-3.5 and a simple model\nattains fully-supervised competitive performance across ten widely used medical\ndatasets. These datasets represent vertically specialized medical diagnostic\nscenarios (e.g., diabetes, heart diseases, COVID-19), highlighting the\npotential of SERVAL in refining the vertical capabilities of LLMs and training\nvertical models from scratch, all achieved without the need for annotations.\nLink: http://arxiv.org/abs/2403.01570v2\n---\n--------------------------------------------------------------------------------\nResearch_Action_1\n(\nto\nchat_manager\n)\n:\nBased on the provided code output, here is a markdown table categorizing the papers by domain, along with their titles, authors, summaries, and links:\n| Domain | Title | Authors | Summary | Link |\n|\n--------\n|\n-------\n|\n---------\n|\n---------\n|\n------\n|\n| Natural Language Processing | Adapting LLMs for Efficient Context Processing through Soft Prompt Compression | Cangqing Wang, et al. | The paper presents a framework for efficient context processing in LLMs using natural language summarization and soft prompt compression. | [Link](http://arxiv.org/abs/2404.04997v1) |\n| Transportation | Explainable Traffic Flow Prediction with Large Language Models | Xusen Guo, et al. | This paper introduces a novel approach for interpretable traffic flow predictions using LLMs, which captures complex spatial-temporal patterns. | [Link](http://arxiv.org/abs/2404.02937v2) |\n| Education | Designing Child-Centric AI Learning Environments: Insights from LLM-Enhanced Creative Project-Based Learning | Siyu Zha, et al. | The study explores the potential of LLMs in enhancing project-based learning (PBL) and fostering creativity in educational settings. | [Link](http://arxiv.org/abs/2403.16159v2) |\n| Mental Health | The opportunities and risks of large language models in mental health | Hannah R. Lawrence, et al. | This review summarizes the literature on LLMs in mental health education, assessment, and intervention, highlighting opportunities and risks. | [Link](http://arxiv.org/abs/2403.14814v2) |\n| Blockchain Security | Large Language Models for Blockchain Security: A Systematic Literature Review | Zheyuan He, et al. | The paper reviews the application of LLMs in blockchain security, discussing their impact and potential limitations. | [Link](http://arxiv.org/abs/2403.14280v2) |\n| Spoken Language Understanding | Do Large Language Model Understand Multi-Intent Spoken Language? | Shangjian Yin, et al. | The study investigates LLMs' capabilities in multi-intent spoken language understanding and proposes new methodologies and metrics. | [Link](http://arxiv.org/abs/2403.04481v2) |\n| Multilingualism | Breaking the Language Barrier: Can Direct Inference Outperform Pre-Translation in Multilingual LLM Applications? | Yotam Intrator, et al. | The paper challenges the pre-translation paradigm in multilingual LLM applications, showing the advantages of direct inference. | [Link](http://arxiv.org/abs/2403.04792v1) |\n| Scientific Literature | SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis | Hengxing Cai, et al. | Introduces SciAssess, a benchmark for evaluating LLMs' abilities in scientific literature analysis across various scientific fields. | [Link](http://arxiv.org/abs/2403.01976v2) |\n| Privacy & Security | Differentially Private Synthetic Data via Foundation Model APIs 2: Text | Chulin Xie, et al. | The paper proposes a method to generate differentially private synthetic text data using API access to LLMs without model training. | [Link](http://arxiv.org/abs/2403.01749v1) |\n| Medical Diagnostics | SERVAL: Synergy Learning between Vertical Models and LLMs towards Oracle-Level Zero-shot Medical Prediction | Jiahuan Yan, et al. | SERVAL is a synergy learning pipeline that enhances the vertical capabilities of LLMs and trains vertical models without annotations in the medical domain. | [Link](http://arxiv.org/abs/2403.01570v2) |\nPlease note that the domains have been inferred from the summaries and titles of the papers and may not perfectly reflect the authors' intended categorization.\n--------------------------------------------------------------------------------"
                    }
                }
            ],
            "subsections": []
        }
    ],
    "images": []
}